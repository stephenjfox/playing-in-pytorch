{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derived from reading through [\"What is `torch.nn` _really_?\"](https://pytorch.org/tutorials/beginner/nn_tutorial.html).\n",
    "* I find this generally ironic, because Jeremy likes to teach from a high-level\n",
    "* This tutorial is going to be everything from the bottom-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://deeplearning.net/data/mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filestructure(filename):\n",
    "    if not (PATH / filename).exists():\n",
    "        content = requests.get(URL + filename).content\n",
    "        (PATH / filename).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_validation_sets(filename):\n",
    "    import pickle\n",
    "    import gzip\n",
    "    \n",
    "    with gzip.open((PATH / filename).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "        return ((x_train, y_train), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually bring in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "make_filestructure(FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a sidenote - this is __totally__ how Jeremy Howard codes:\n",
    "1. Very brief, but super-effective, blocks of code\n",
    "2. No comments, but the code is so _direct_ that the given assumption that you can code in Python is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train, xy_valid = load_train_validation_sets(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_digit(images_flat):\n",
    "    from matplotlib import pyplot\n",
    "    import numpy as np\n",
    "    \n",
    "    random_index = np.random.randint(len(images_flat), size=1)[0]\n",
    "    # show our random image in grayscale\n",
    "    pyplot.imshow(images_flat[random_index].reshape((28, 28)), cmap=\"gray\")\n",
    "    print(\"images.shape =\", images_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape = (50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pass in the training set, but it doesn't really matter which one we look at\n",
    "show_one_digit(xy_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch-ify me cap'n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_np_to_torch(images_as_numpy):\n",
    "    '''\n",
    "    Args:\n",
    "        images_as_numpy: all data as np.array's, concatenated together.\n",
    "            I.e. (x_train, y_train, x_val, y_val[, x_test, y_test])\n",
    "    '''\n",
    "    return map(torch.tensor, (*images_as_numpy,))\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = convert_np_to_torch((*xy_train, *xy_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4,  ..., 8, 4, 8]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 784 from torch.Size([50000, 784])\n"
     ]
    }
   ],
   "source": [
    "n, c = x_train.shape # number of samples, columns (?)\n",
    "print(n, c, 'from', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_weights_and_biases():\n",
    "    '''Return (weights, bias) constructed from a Normal Distribution, and \"Xavier-initialized\"'''\n",
    "    import math\n",
    "    \n",
    "    weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "    weights.requires_grad_() # set requires_grad = True post-hoc\n",
    "    \n",
    "    bias = torch.zeros(10, requires_grad=True)\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because PyTorch can construct optimized GPU code (with a cuDNN optimizing compiler?) we're going to write two\n",
    "  functions for use\n",
    "1. A \"softmax\" function, which predicts a probability distribution\n",
    "2. A \"model\" function, because anything that is invocable can be a PyTorch model\n",
    "  * And the gradients will still be calculated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_model():\n",
    "    '''To encapsulate the shenanigans that are about to ensue, I will work in a function'''\n",
    "    \n",
    "    def log_softmax(x):\n",
    "        return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "    def model(mini_batch, weights, bias):\n",
    "        return log_softmax(mini_batch @ weights + bias)\n",
    "    \n",
    "    w, b = mnist_weights_and_biases()\n",
    "    \n",
    "    bs = 64 # batch size\n",
    "    \n",
    "    x_b = x_train[0:bs] # a mini-batch from our inputs\n",
    "    predictions = model(x_b, w, b)\n",
    "    \n",
    "    print('Prediction 1:', predictions[0])\n",
    "    print('predictions.shape', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: tensor([-2.2249, -2.5399, -2.2281, -2.3276, -2.1397, -2.2130, -2.7316, -2.3885,\n",
      "        -2.0396, -2.3669], grad_fn=<SelectBackward>)\n",
      "predictions.shape torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "simple_linear_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for the sake of keeping the global namespace relatively unpolluted (until we get to the `torch.nn` stuff)\n",
    "  I'm going to simple rewrite `simple_linear_model`.\n",
    "* With the caviate of pulling up `log_softmax(x)` for its general utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _feeling_out_torch_sum():\n",
    "    # give me [0, 120) and arrange the as 4 blocks of 5x6 matrices\n",
    "    b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n",
    "    \n",
    "    a = torch.arange(10 * 2).view(2, 10)\n",
    "    print(a)\n",
    "    print(a.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "tensor([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])\n"
     ]
    }
   ],
   "source": [
    "_feeling_out_torch_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?torch.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _feeling_out_torch_unsqueeze():\n",
    "#     ?torch.unsqueeze\n",
    "    small_range = torch.arange(1., 3., .5)\n",
    "    print(small_range)\n",
    "    \n",
    "    _sum = small_range.sum()\n",
    "    print(_sum)\n",
    "    \n",
    "    print(_sum.unsqueeze(-1))\n",
    "    print(_sum.log())\n",
    "    print(_sum.log().unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.5000, 2.0000, 2.5000])\n",
      "tensor(7.)\n",
      "tensor([7.])\n",
      "tensor(1.9459)\n",
      "tensor([1.9459])\n"
     ]
    }
   ],
   "source": [
    "_feeling_out_torch_unsqueeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Log) Softmax, here, is the difference of\n",
    "1. the input, and\n",
    "2. the log of the sum along the last dimension of the exponential of the input\n",
    "\n",
    "Then it just boxes that log.\n",
    "* Why index `-1` rather than `0` for a scalar value? I don't know, but maybe we can find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.]]), tensor([[0.]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1).unsqueeze(-1), torch.Tensor(1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No difference when there's one element, but how about with multiple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00],\n",
       "         [-3.6893e+19],\n",
       "         [ 1.0140e+16]]), tensor([[ 0.0000e+00, -3.6893e+19,  1.0149e+16]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(3).unsqueeze(-1), torch.Tensor(3).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is. `unsqueeze(-1)` is guaranteed to box the elements.\n",
    "* If, for some reason, the last dimension in your sum was a vector, this `unsqueeze` would make sure that\n",
    "  you have individually boxes elements (in this case, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Another token Jeremy Howard-ism:\n",
    "* Great coding practices, but he doesn't explain them along the way.\n",
    "* He wants you to trust his implementation, and know enough to dig in yourself (as I have done above)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(x, target):\n",
    "    return -x[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, target_batch):\n",
    "    preds = torch.argmax(out, dim=1) # this is weird to me\n",
    "    return (preds == target_batch).float().mean() # average accuracy of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?torch.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets the indices of the maximum values of the rows of the linear regression...\n",
    "* Why is that how we determine out prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_model():\n",
    "    '''To encapsulate the shenanigans that are about to ensue, I will work in a function'''\n",
    "\n",
    "    w, b = mnist_weights_and_biases()\n",
    "    \n",
    "    def model(mini_batch):\n",
    "        return log_softmax(mini_batch @ w + b)\n",
    "    \n",
    "    \n",
    "    bs = 64 # batch size\n",
    "    \n",
    "    x_b = x_train[0:bs] # a mini-batch from our inputs\n",
    "    predictions = model(x_b)\n",
    "    \n",
    "    print('Prediction 1:', predictions[0])\n",
    "    print('predictions.shape', predictions.shape)\n",
    "    \n",
    "    loss_func = neg_log_likelihood\n",
    "    \n",
    "    y_b = y_train[0:bs]\n",
    "    \n",
    "    print(loss_func(predictions, y_b))\n",
    "    \n",
    "    lr = 0.5\n",
    "    epochs = 2 # how many laps through the dataset\n",
    "\n",
    "    print(f\"training our model {epochs} epochs with learning rate of {lr}\")\n",
    "    for epoch in range(epochs):\n",
    "        # this 'i' is sometimes called a \"period\" when iterating through the dataset\n",
    "        for i in range((n - 1) // bs + 1): # why n-1?\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs # now we have a range [i*bs, (i+1)*bs)\n",
    "            \n",
    "            x_mini_batch = x_train[start_i: end_i]\n",
    "            y_mini_batch = y_train[start_i: end_i]\n",
    "            \n",
    "            prediction = model(x_mini_batch) # prediction matrix of matrices (\"tensor\")\n",
    "            loss = loss_func(prediction, y_mini_batch)\n",
    "            \n",
    "            if i % 100 == 0: # do some logging every 20th batch\n",
    "                print(f' Loss of {loss}, with batch accuracy of {accuracy(prediction, y_mini_batch)}')\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                w -= w.grad * lr\n",
    "                b -= b.grad * lr\n",
    "                w.grad.zero_()\n",
    "                b.grad.zero_()\n",
    "    \n",
    "    print(loss_func(model(x_b), y_b), accuracy(model(x_b), y_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: tensor([-2.6693, -1.9444, -2.4209, -2.5773, -1.7092, -1.8297, -3.0054, -2.6381,\n",
      "        -2.5624, -2.4865], grad_fn=<SelectBackward>)\n",
      "predictions.shape torch.Size([64, 10])\n",
      "tensor(2.3040, grad_fn=<NegBackward>)\n",
      "training our model 2 epochs with learning rate of 0.5\n",
      " Loss of 2.3039698600769043, with batch accuracy of 0.09375\n",
      " Loss of 0.3145824670791626, with batch accuracy of 0.90625\n",
      " Loss of 0.30414271354675293, with batch accuracy of 0.875\n",
      " Loss of 0.39955586194992065, with batch accuracy of 0.921875\n",
      " Loss of 0.23822332918643951, with batch accuracy of 0.890625\n",
      " Loss of 0.3744773268699646, with batch accuracy of 0.890625\n",
      " Loss of 0.26767498254776, with batch accuracy of 0.890625\n",
      " Loss of 0.3798275589942932, with batch accuracy of 0.90625\n",
      " Loss of 0.2802697420120239, with batch accuracy of 0.921875\n",
      " Loss of 0.263016015291214, with batch accuracy of 0.921875\n",
      " Loss of 0.19756793975830078, with batch accuracy of 0.90625\n",
      " Loss of 0.34718382358551025, with batch accuracy of 0.921875\n",
      " Loss of 0.21082603931427002, with batch accuracy of 0.9375\n",
      " Loss of 0.3482421338558197, with batch accuracy of 0.90625\n",
      " Loss of 0.22872313857078552, with batch accuracy of 0.90625\n",
      " Loss of 0.3648742735385895, with batch accuracy of 0.890625\n",
      "tensor(0.2288, grad_fn=<NegBackward>) tensor(0.9531)\n"
     ]
    }
   ],
   "source": [
    "simple_linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
