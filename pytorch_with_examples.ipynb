{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch, with Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: numpy\n",
    "\n",
    "PyTorch was designed to play nice with `numpy` and to be easily approachable for the `scipy` community.\n",
    "\n",
    "* Here's a brief code snippet of a neural network, in plain `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some of the dimensions of our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is the input dimension\n",
    "# H is the hidden dimension; D_out is the output dimension\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll generate some input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(N, D_in) # random domain\n",
    "y = np.random.randn(N, D_out) # random range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: there is no real association between these data, but that's kind of the beauty of neural networks\n",
    "\n",
    "> they can find a relation between ***anything***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totally random. There are certain initialization strategies that produce interesting results\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6 # I still don't understand why we must have such small learning rates... For later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE = 37622490.015085936\n",
      "Epoch 2: MSE = 36740429.387162045\n",
      "Epoch 3: MSE = 36346370.803715\n",
      "Epoch 4: MSE = 31166474.54507366\n",
      "Epoch 5: MSE = 21263080.69249659\n",
      "Epoch 6: MSE = 11883437.543800661\n",
      "Epoch 7: MSE = 6052430.955304505\n",
      "Epoch 8: MSE = 3248142.1550662685\n",
      "Epoch 9: MSE = 1994191.1053333716\n",
      "Epoch 10: MSE = 1400119.4344981094\n",
      "Epoch 11: MSE = 1076313.8774243798\n",
      "Epoch 12: MSE = 870496.4168298907\n",
      "Epoch 13: MSE = 723836.7326850488\n",
      "Epoch 14: MSE = 611249.6067232866\n",
      "Epoch 15: MSE = 521401.89185734035\n",
      "Epoch 16: MSE = 448031.54385428975\n",
      "Epoch 17: MSE = 387221.90539018763\n",
      "Epoch 18: MSE = 336339.29848937975\n",
      "Epoch 19: MSE = 293440.9006627762\n",
      "Epoch 20: MSE = 257122.530262462\n",
      "Epoch 21: MSE = 226147.06734315926\n",
      "Epoch 22: MSE = 199629.66639914905\n",
      "Epoch 23: MSE = 176793.80393566357\n",
      "Epoch 24: MSE = 157039.77482901997\n",
      "Epoch 25: MSE = 139887.5259576905\n",
      "Epoch 26: MSE = 124939.05881027838\n",
      "Epoch 27: MSE = 111856.8035350833\n",
      "Epoch 28: MSE = 100382.20329090534\n",
      "Epoch 29: MSE = 90307.76120341709\n",
      "Epoch 30: MSE = 81444.52135640537\n",
      "Epoch 31: MSE = 73595.21365082823\n",
      "Epoch 32: MSE = 66629.57584738222\n",
      "Epoch 33: MSE = 60444.966482263524\n",
      "Epoch 34: MSE = 54931.93676779508\n",
      "Epoch 35: MSE = 50006.848724707015\n",
      "Epoch 36: MSE = 45596.79277688825\n",
      "Epoch 37: MSE = 41639.23889505158\n",
      "Epoch 38: MSE = 38079.51397700255\n",
      "Epoch 39: MSE = 34871.16743938834\n",
      "Epoch 40: MSE = 31975.41025322792\n",
      "Epoch 41: MSE = 29360.067343754774\n",
      "Epoch 42: MSE = 26991.701706119715\n",
      "Epoch 43: MSE = 24843.483745910293\n",
      "Epoch 44: MSE = 22891.185837108977\n",
      "Epoch 45: MSE = 21115.061912432917\n",
      "Epoch 46: MSE = 19498.638860107658\n",
      "Epoch 47: MSE = 18024.78075805954\n",
      "Epoch 48: MSE = 16678.75205242408\n",
      "Epoch 49: MSE = 15447.344096335008\n",
      "Epoch 50: MSE = 14319.899368361475\n",
      "Epoch 51: MSE = 13285.466557768694\n",
      "Epoch 52: MSE = 12336.119591020943\n",
      "Epoch 53: MSE = 11463.162153689505\n",
      "Epoch 54: MSE = 10659.909095468287\n",
      "Epoch 55: MSE = 9920.40806551743\n",
      "Epoch 56: MSE = 9238.421788313175\n",
      "Epoch 57: MSE = 8609.145803742378\n",
      "Epoch 58: MSE = 8029.990136872516\n",
      "Epoch 59: MSE = 7494.651126427445\n",
      "Epoch 60: MSE = 6999.497155671023\n",
      "Epoch 61: MSE = 6540.913097309706\n",
      "Epoch 62: MSE = 6115.791657327327\n",
      "Epoch 63: MSE = 5721.552148502178\n",
      "Epoch 64: MSE = 5355.600123107515\n",
      "Epoch 65: MSE = 5015.629171967983\n",
      "Epoch 66: MSE = 4699.5468742559515\n",
      "Epoch 67: MSE = 4405.442408380069\n",
      "Epoch 68: MSE = 4131.632988494695\n",
      "Epoch 69: MSE = 3876.5715560982703\n",
      "Epoch 70: MSE = 3638.850676055186\n",
      "Epoch 71: MSE = 3417.1801626220245\n",
      "Epoch 72: MSE = 3210.273781857944\n",
      "Epoch 73: MSE = 3017.015859282298\n",
      "Epoch 74: MSE = 2836.484904326321\n",
      "Epoch 75: MSE = 2667.8344456066266\n",
      "Epoch 76: MSE = 2510.106103531559\n",
      "Epoch 77: MSE = 2362.4679268002164\n",
      "Epoch 78: MSE = 2224.237537923529\n",
      "Epoch 79: MSE = 2094.7885431228947\n",
      "Epoch 80: MSE = 1973.5041687720138\n",
      "Epoch 81: MSE = 1859.814568985171\n",
      "Epoch 82: MSE = 1753.1925968595983\n",
      "Epoch 83: MSE = 1653.158460531903\n",
      "Epoch 84: MSE = 1559.279843972198\n",
      "Epoch 85: MSE = 1471.1154808631138\n",
      "Epoch 86: MSE = 1388.3101191328692\n",
      "Epoch 87: MSE = 1310.5043894388007\n",
      "Epoch 88: MSE = 1237.3944535569044\n",
      "Epoch 89: MSE = 1168.626212288745\n",
      "Epoch 90: MSE = 1103.9880559018156\n",
      "Epoch 91: MSE = 1043.1350567531515\n",
      "Epoch 92: MSE = 985.8622319615803\n",
      "Epoch 93: MSE = 931.9422196516321\n",
      "Epoch 94: MSE = 881.1697472894778\n",
      "Epoch 95: MSE = 833.3389650133092\n",
      "Epoch 96: MSE = 788.2567058023138\n",
      "Epoch 97: MSE = 745.7636106284749\n",
      "Epoch 98: MSE = 705.7056896880861\n",
      "Epoch 99: MSE = 667.9178714056623\n",
      "Epoch 100: MSE = 632.2691623974492\n",
      "Epoch 101: MSE = 598.6339755702711\n",
      "Epoch 102: MSE = 566.8876310206349\n",
      "Epoch 103: MSE = 536.9154851141278\n",
      "Epoch 104: MSE = 508.61990050655635\n",
      "Epoch 105: MSE = 481.89090463051417\n",
      "Epoch 106: MSE = 456.6381988821844\n",
      "Epoch 107: MSE = 432.783607880228\n",
      "Epoch 108: MSE = 410.48277294896417\n",
      "Epoch 109: MSE = 389.4424071406002\n",
      "Epoch 110: MSE = 369.5430564451211\n",
      "Epoch 111: MSE = 350.71842661737185\n",
      "Epoch 112: MSE = 332.92139919121337\n",
      "Epoch 113: MSE = 316.0774920210373\n",
      "Epoch 114: MSE = 300.1351636893156\n",
      "Epoch 115: MSE = 285.0381954546131\n",
      "Epoch 116: MSE = 270.7404639486755\n",
      "Epoch 117: MSE = 257.19670074761916\n",
      "Epoch 118: MSE = 244.36720267472109\n",
      "Epoch 119: MSE = 232.2138051971009\n",
      "Epoch 120: MSE = 220.69199463142877\n",
      "Epoch 121: MSE = 209.7661723973341\n",
      "Epoch 122: MSE = 199.4071236426222\n",
      "Epoch 123: MSE = 189.5837266302214\n",
      "Epoch 124: MSE = 180.26770852817907\n",
      "Epoch 125: MSE = 171.43056421091256\n",
      "Epoch 126: MSE = 163.04700109447631\n",
      "Epoch 127: MSE = 155.0932156714547\n",
      "Epoch 128: MSE = 147.54211989620427\n",
      "Epoch 129: MSE = 140.37524105670514\n",
      "Epoch 130: MSE = 133.57131116137026\n",
      "Epoch 131: MSE = 127.11118699466655\n",
      "Epoch 132: MSE = 120.97510726238451\n",
      "Epoch 133: MSE = 115.1500593266217\n",
      "Epoch 134: MSE = 109.61696288671399\n",
      "Epoch 135: MSE = 104.36072649414182\n",
      "Epoch 136: MSE = 99.36264621690431\n",
      "Epoch 137: MSE = 94.61524115438569\n",
      "Epoch 138: MSE = 90.10201108422906\n",
      "Epoch 139: MSE = 85.81321976667735\n",
      "Epoch 140: MSE = 81.73536708895087\n",
      "Epoch 141: MSE = 77.85935399138833\n",
      "Epoch 142: MSE = 74.17661905737344\n",
      "Epoch 143: MSE = 70.67384043475671\n",
      "Epoch 144: MSE = 67.34179187858503\n",
      "Epoch 145: MSE = 64.17309172927605\n",
      "Epoch 146: MSE = 61.15881202636159\n",
      "Epoch 147: MSE = 58.29061471903296\n",
      "Epoch 148: MSE = 55.56252199237481\n",
      "Epoch 149: MSE = 52.96548690780739\n",
      "Epoch 150: MSE = 50.49371318521442\n",
      "Epoch 151: MSE = 48.14103256536296\n",
      "Epoch 152: MSE = 45.900438477685476\n",
      "Epoch 153: MSE = 43.76827370943535\n",
      "Epoch 154: MSE = 41.737911557055334\n",
      "Epoch 155: MSE = 39.805495155331165\n",
      "Epoch 156: MSE = 37.96373680532845\n",
      "Epoch 157: MSE = 36.21069989768719\n",
      "Epoch 158: MSE = 34.540764751522495\n",
      "Epoch 159: MSE = 32.951435036374235\n",
      "Epoch 160: MSE = 31.436047276050854\n",
      "Epoch 161: MSE = 29.99268571596977\n",
      "Epoch 162: MSE = 28.61725720732948\n",
      "Epoch 163: MSE = 27.307665494828036\n",
      "Epoch 164: MSE = 26.058949573043684\n",
      "Epoch 165: MSE = 24.8684011145698\n",
      "Epoch 166: MSE = 23.733897311168725\n",
      "Epoch 167: MSE = 22.652094689715945\n",
      "Epoch 168: MSE = 21.62150089986359\n",
      "Epoch 169: MSE = 20.638597076446004\n",
      "Epoch 170: MSE = 19.70164825076436\n",
      "Epoch 171: MSE = 18.807728317947152\n",
      "Epoch 172: MSE = 17.95582418275105\n",
      "Epoch 173: MSE = 17.14332790970797\n",
      "Epoch 174: MSE = 16.368535728347087\n",
      "Epoch 175: MSE = 15.62932126670194\n",
      "Epoch 176: MSE = 14.92431036040131\n",
      "Epoch 177: MSE = 14.251894466362753\n",
      "Epoch 178: MSE = 13.610912543222266\n",
      "Epoch 179: MSE = 12.99894872141507\n",
      "Epoch 180: MSE = 12.414892795525969\n",
      "Epoch 181: MSE = 11.857782129139185\n",
      "Epoch 182: MSE = 11.325988247419652\n",
      "Epoch 183: MSE = 10.818933071193662\n",
      "Epoch 184: MSE = 10.334869982949028\n",
      "Epoch 185: MSE = 9.872871054265548\n",
      "Epoch 186: MSE = 9.43184308696091\n",
      "Epoch 187: MSE = 9.01100247206937\n",
      "Epoch 188: MSE = 8.609361138442639\n",
      "Epoch 189: MSE = 8.225933745553025\n",
      "Epoch 190: MSE = 7.859858102025809\n",
      "Epoch 191: MSE = 7.510346081176843\n",
      "Epoch 192: MSE = 7.1767015896219375\n",
      "Epoch 193: MSE = 6.858227927583304\n",
      "Epoch 194: MSE = 6.554249469602681\n",
      "Epoch 195: MSE = 6.2638294672766985\n",
      "Epoch 196: MSE = 5.98646277327442\n",
      "Epoch 197: MSE = 5.721577159292783\n",
      "Epoch 198: MSE = 5.468629902411028\n",
      "Epoch 199: MSE = 5.2271750737179\n",
      "Epoch 200: MSE = 4.996401144559115\n",
      "Epoch 201: MSE = 4.776073943213712\n",
      "Epoch 202: MSE = 4.56553408521772\n",
      "Epoch 203: MSE = 4.36447443296842\n",
      "Epoch 204: MSE = 4.172457738932574\n",
      "Epoch 205: MSE = 3.9890221247586664\n",
      "Epoch 206: MSE = 3.813715878476743\n",
      "Epoch 207: MSE = 3.6462301943326354\n",
      "Epoch 208: MSE = 3.486241093561362\n",
      "Epoch 209: MSE = 3.3334193284485236\n",
      "Epoch 210: MSE = 3.1874299112743136\n",
      "Epoch 211: MSE = 3.047823501377257\n",
      "Epoch 212: MSE = 2.914456143127659\n",
      "Epoch 213: MSE = 2.787017008610114\n",
      "Epoch 214: MSE = 2.6651926434700917\n",
      "Epoch 215: MSE = 2.5488343174075254\n",
      "Epoch 216: MSE = 2.4375748082164224\n",
      "Epoch 217: MSE = 2.3312749136139272\n",
      "Epoch 218: MSE = 2.2296201461344753\n",
      "Epoch 219: MSE = 2.1324937438477756\n",
      "Epoch 220: MSE = 2.039643172105424\n",
      "Epoch 221: MSE = 1.9509237942000897\n",
      "Epoch 222: MSE = 1.8660956995850624\n",
      "Epoch 223: MSE = 1.7849672264080563\n",
      "Epoch 224: MSE = 1.7074517505818325\n",
      "Epoch 225: MSE = 1.6333389870260135\n",
      "Epoch 226: MSE = 1.5624992128205226\n",
      "Epoch 227: MSE = 1.494770243341998\n",
      "Epoch 228: MSE = 1.4299819486997594\n",
      "Epoch 229: MSE = 1.3680534853179482\n",
      "Epoch 230: MSE = 1.308810215962765\n",
      "Epoch 231: MSE = 1.2521987577081548\n",
      "Epoch 232: MSE = 1.1980438485757061\n",
      "Epoch 233: MSE = 1.1462894560919306\n",
      "Epoch 234: MSE = 1.0967668495652643\n",
      "Epoch 235: MSE = 1.0494181815190289\n",
      "Epoch 236: MSE = 1.00413780121444\n",
      "Epoch 237: MSE = 0.9608168764057278\n"
     ]
    }
   ],
   "source": [
    "for t in range(1, 501):\n",
    "    # forward pass (or propogation): compute a y-prediction\n",
    "    h = x.dot(w1) # interim value between matrix multiplication and activation function\n",
    "    h_relu = np.maximum(h, 0) # the aforementioned activation\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # Compute loss\n",
    "    mse = np.square(y_pred - y).sum() # mean squared-error (np.square is element-wise square calculation)\n",
    "    print(f\"Epoch {t}: MSE = {mse}\")\n",
    "    \n",
    "    if mse < 1:\n",
    "        break\n",
    "    \n",
    "    # Backpropogate: compute gradients of w1 and w2, with respect to loss (partial derivative)\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0 # assert: 0-activations have a 0 derivation\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # update weights accordingly\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
